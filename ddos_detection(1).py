# -*- coding: utf-8 -*-
"""DDos-Detection(1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1G5CXxceuVqOu-GUKFTeStx--2XPszYXz
"""

import pandas as pd
import sklearn.ensemble as es
import sklearn.tree as tr
import sklearn.neighbors as n
import sklearn.neural_network as nn
import sklearn.svm as s
import sklearn.utils as u
import sklearn.feature_selection as fs
import time as t
import numpy as np
import sklearn.metrics as m
import sklearn.preprocessing as pp
import matplotlib.pyplot as plt
import seaborn as sb
import pickle

import warnings as w
w.filterwarnings('ignore')

countR = 0
count21R = 0
countD = 0
count21D = 0
countK = 0
count21K = 0
countS = 0
count21S = 0
countM = 0
count21M = 0
countNorm = 0
countDoS = 0
countProbe = 0
countR2L = 0
countU2R = 0

#Start of Reading Data


traindata = pd.read_csv("/content/KDDTest+.csv")
testdata21 = pd.read_csv("/content/KDDTest-21+.csv")
testdata = pd.read_csv("/content/KDDTrain+.csv")

#Start of Preprocessing

traindata = u.shuffle(traindata)
testdata = u.shuffle(testdata)
testdata21 = u.shuffle(testdata21)

atk_dict = {
    'normal': 'Normal',
    'back': 'DoS',
    'land': 'DoS',
    'neptune': 'DoS',
    'pod': 'DoS',
    'smurf': 'DoS',
    'teardrop': 'DoS',
    'mailbomb': 'DoS',
    'apache2': 'DoS',
    'processtable': 'DoS',
    'udpstorm': 'DoS',
    'ipsweep': 'Probe',
    'nmap': 'Probe',
    'portsweep': 'Probe',
    'satan': 'Probe',
    'mscan': 'Probe',
    'saint': 'Probe',
    'ftp_write': 'R2L',
    'guess_passwd': 'R2L',
    'imap': 'R2L',
    'multihop': 'R2L',
    'phf': 'R2L',
    'spy': 'R2L',
    'warezclient': 'R2L',
    'warezmaster': 'R2L',
    'sendmail': 'R2L',
    'named': 'R2L',
    'snmpgetattack': 'R2L',
    'snmpguess': 'R2L',
    'xlock': 'R2L',
    'xsnoop': 'R2L',
    'worm': 'R2L',
    'buffer_overflow': 'U2R',
    'loadmodule': 'U2R',
    'perl': 'U2R',
    'rootkit': 'U2R',
    'httptunnel': 'U2R',
    'ps': 'U2R',
    'sqlattack': 'U2R',
    'xterm': 'U2R'
}

atk_correct = {"Normal":1, "DoS":2, "Probe":3, "R2L":4, "U2R":5}

protocol_correct = {"tcp": 1, "icmp" : 2, "udp" : 3}

flag_correct = {"SF":1, "REJ":2, "RSTR":3, "RSTO":4, "S0":5, "S1":6, "S2":7, "S3":8, "OTH":9, "SH":10, "RSTOS0":11}

print("\nTrain data difficulty level count graph: \n")
t.sleep(1)
ax = sb.countplot(x='Difficulty Level', data=testdata)
plt.show()

print("\nTest data difficulty level count graph:\n")
t.sleep(1)
ax = sb.countplot(x='Difficulty Level', data=traindata)
plt.show()

print("\nTest data without difficulty level 21 difficulty level count graph:\n")
ax = sb.countplot(x='Difficulty Level', data=testdata21)
plt.show()

print("\nTrain data protocol count graph: \n")
t.sleep(1)
ax = sb.countplot(x='Protocol_Type', data=testdata)
for p in ax.patches:
    ax.annotate('{:.2f}%'.format((p.get_height() * 100) / len(testdata)), (p.get_x() + 0.22, p.get_height() + 2))
plt.show()

print("\nTest data protocol count graph:\n")
t.sleep(1)
ax = sb.countplot(x='Protocol_Type', data=traindata)
for p in ax.patches:
    ax.annotate('{:.2f}%'.format((p.get_height() * 100) / len(traindata)), (p.get_x() + 0.22, p.get_height() + 2))
plt.show()

print("\nTest data without difficulty level 21 protocol count graph:\n")
t.sleep(1)
ax = sb.countplot(x='Protocol_Type', data=testdata21)
for p in ax.patches:
    ax.annotate('{:.2f}%'.format((p.get_height() * 100) / len(testdata21)), (p.get_x() + 0.22, p.get_height() + 2))
plt.show()

traindata = traindata.drop(["Duration"], axis=1)
testdata = testdata.drop(["Duration"], axis=1)
testdata21 = testdata21.drop(["Duration"], axis=1)

traindata = traindata.drop(["Service"], axis=1)
testdata = testdata.drop(["Service"], axis=1)
testdata21 = testdata21.drop(["Service"], axis=1)


traindata = traindata.drop(["Dst_Bytes"], axis=1)
testdata = testdata.drop(["Dst_Bytes"], axis=1)
testdata21 = testdata21.drop(["Dst_Bytes"], axis=1)


traindata = traindata.drop(["Land"], axis=1)
testdata = testdata.drop(["Land"], axis=1)
testdata21 = testdata21.drop(["Land"], axis=1)


traindata = traindata.drop(["Wrong_Fragment"], axis=1)
testdata = testdata.drop(["Wrong_Fragment"], axis=1)
testdata21 = testdata21.drop(["Wrong_Fragment"], axis=1)


traindata = traindata.drop(["Urgent"], axis=1)
testdata = testdata.drop(["Urgent"], axis=1)
testdata21 = testdata21.drop(["Urgent"], axis=1)


traindata = traindata.drop(["Hot"], axis=1)
testdata = testdata.drop(["Hot"], axis=1)
testdata21 = testdata21.drop(["Hot"], axis=1)


traindata = traindata.drop(["Num_Failed_Logins"], axis=1)
testdata = testdata.drop(["Num_Failed_Logins"], axis=1)
testdata21 = testdata21.drop(["Num_Failed_Logins"], axis=1)


traindata = traindata.drop(["Logged_In"], axis=1)
testdata = testdata.drop(["Logged_In"], axis=1)
testdata21 = testdata21.drop(["Logged_In"], axis=1)


traindata = traindata.drop(["Num_Compromised"], axis=1)
testdata = testdata.drop(["Num_Compromised"], axis=1)
testdata21 = testdata21.drop(["Num_Compromised"], axis=1)


traindata = traindata.drop(["Root_Shell"], axis=1)
testdata = testdata.drop(["Root_Shell"], axis=1)
testdata21 = testdata21.drop(["Root_Shell"], axis=1)


traindata = traindata.drop(["Su_Attempted"], axis=1)
testdata = testdata.drop(["Su_Attempted"], axis=1)
testdata21 = testdata21.drop(["Su_Attempted"], axis=1)


traindata = traindata.drop(["Num_Root"], axis=1)
testdata = testdata.drop(["Num_Root"], axis=1)
testdata21 = testdata21.drop(["Num_Root"], axis=1)

traindata = traindata.drop(["Num_File_Creations"], axis=1)
testdata = testdata.drop(["Num_File_Creations"], axis=1)
testdata21 = testdata21.drop(["Num_File_Creations"], axis=1)


traindata = traindata.drop(["Num_Shells"], axis=1)
testdata = testdata.drop(["Num_Shells"], axis=1)
testdata21 = testdata21.drop(["Num_Shells"], axis=1)


traindata = traindata.drop(["Num_Outbound_Cmds"], axis=1)
testdata = testdata.drop(["Num_Outbound_Cmds"], axis=1)
testdata21 = testdata21.drop(["Num_Outbound_Cmds"], axis=1)


traindata = traindata.drop(["Is_Host_Login"], axis=1)
testdata = testdata.drop(["Is_Host_Login"], axis=1)
testdata21 = testdata21.drop(["Is_Host_Login"], axis=1)


traindata = traindata.drop(["Count"], axis=1)
testdata = testdata.drop(["Count"], axis=1)
testdata21 = testdata21.drop(["Count"], axis=1)


traindata = traindata.drop(["Serror_Rate"], axis=1)
testdata = testdata.drop(["Serror_Rate"], axis=1)
testdata21 = testdata21.drop(["Serror_Rate"], axis=1)


traindata = traindata.drop(["Srv_Serror_Rate"], axis=1)
testdata = testdata.drop(["Srv_Serror_Rate"], axis=1)
testdata21 = testdata21.drop(["Srv_Serror_Rate"], axis=1)


traindata = traindata.drop(["Rerror_Rate"], axis=1)
testdata = testdata.drop(["Rerror_Rate"], axis=1)
testdata21 = testdata21.drop(["Rerror_Rate"], axis=1)


traindata = traindata.drop(["Srv_Rerror_Rate"], axis=1)
testdata = testdata.drop(["Srv_Rerror_Rate"], axis=1)
testdata21 = testdata21.drop(["Srv_Rerror_Rate"], axis=1)


traindata = traindata.drop(["Same_Srv_Rate"], axis=1)
testdata = testdata.drop(["Same_Srv_Rate"], axis=1)
testdata21 = testdata21.drop(["Same_Srv_Rate"], axis=1)


traindata = traindata.drop(["Dst_Host_Count"], axis=1)
testdata = testdata.drop(["Dst_Host_Count"], axis=1)
testdata21 = testdata21.drop(["Dst_Host_Count"], axis=1)


traindata = traindata.drop(["Dst_Host_Srv_Count"], axis=1)
testdata = testdata.drop(["Dst_Host_Srv_Count"], axis=1)
testdata21 = testdata21.drop(["Dst_Host_Srv_Count"], axis=1)


traindata = traindata.drop(["Dst_Host_Same_Srv_Rate"], axis=1)
testdata = testdata.drop(["Dst_Host_Same_Srv_Rate"], axis=1)
testdata21 = testdata21.drop(["Dst_Host_Same_Srv_Rate"], axis=1)


traindata = traindata.drop(["Dst_Host_Diff_Srv_Rate"], axis=1)
testdata = testdata.drop(["Dst_Host_Diff_Srv_Rate"], axis=1)
testdata21 = testdata21.drop(["Dst_Host_Diff_Srv_Rate"], axis=1)


traindata = traindata.drop(["Dst_Host_Serror_Rate"], axis=1)
testdata = testdata.drop(["Dst_Host_Serror_Rate"], axis=1)
testdata21 = testdata21.drop(["Dst_Host_Serror_Rate"], axis=1)


traindata = traindata.drop(["Dst_Host_Rerror_Rate"], axis=1)
testdata = testdata.drop(["Dst_Host_Rerror_Rate"], axis=1)
testdata21 = testdata21.drop(["Dst_Host_Rerror_Rate"], axis=1)


traindata = traindata.replace({"Class": atk_dict})
testdata = testdata.replace({"Class": atk_dict})
testdata21 = testdata21.replace({"Class": atk_dict})

normTest = testdata[testdata.Class == "Normal"]
normTest21 = testdata21[testdata21.Class == "Normal"]


DoSTest = testdata[testdata.Class == "DoS"]
DoSTest21 = testdata21[testdata21.Class == "DoS"]


probeTest = testdata[testdata.Class == "Probe"]
probeTest21 = testdata21[testdata21.Class == "Probe"]


R2LTest = testdata[testdata.Class == "R2L"]
R2LTest21 = testdata21[testdata21.Class == "R2L"]


U2RTest = testdata[testdata.Class == "U2R"]
U2RTest21 = testdata21[testdata21.Class == "U2R"]

print("Train data attack count graph: \n")
t.sleep(1)
ax = sb.countplot(x='Class', data=testdata)
for p in ax.patches:
    ax.annotate('{:.2f}%'.format((p.get_height() * 100) / len(testdata)), (p.get_x() + 0.22, p.get_height() + 2))
plt.show()

print("\nTest data attack count graph:\n")
t.sleep(1)
ax = sb.countplot(x='Class', data=traindata)
for p in ax.patches:
    ax.annotate('{:.2f}%'.format((p.get_height() * 100) / len(traindata)), (p.get_x() + 0.22, p.get_height() + 2))
plt.show()

print("\nTest data without difficulty level 21 attack count graph:\n")
t.sleep(1)
ax = sb.countplot(x='Class', data=testdata21)
for p in ax.patches:
    ax.annotate('{:.2f}%'.format((p.get_height() * 100) / len(testdata21)), (p.get_x() + 0.22, p.get_height() + 2))
plt.show()

traindata = traindata.replace({"Class": atk_correct})
testdata = testdata.replace({"Class": atk_correct})
testdata21 = testdata21.replace({"Class": atk_correct})


traindata = traindata.replace({"Protocol_Type": protocol_correct})
testdata = testdata.replace({"Protocol_Type": protocol_correct})
testdata21 = testdata21.replace({"Protocol_Type": protocol_correct})

traindata = traindata.replace({"Flag": flag_correct})
testdata = testdata.replace({"Flag": flag_correct})
testdata21 = testdata21.replace({"Flag": flag_correct})

for col in traindata.columns:
    if traindata[col].dtype == type(object):
        le = pp.LabelEncoder()
        traindata[col] = le.fit_transform(traindata[col])

for col in testdata.columns:
    if testdata[col].dtype == type(object):
        le = pp.LabelEncoder()
        testdata[col] = le.fit_transform(testdata[col])

for col in testdata21.columns:
    if testdata21[col].dtype == type(object):
        le = pp.LabelEncoder()
        testdata21[col] = le.fit_transform(testdata21[col])

#End of Preprocessing


#Start of Feature Selection


featsTrainD = traindata.values[:,0:12]

lblsTrainD = traindata.values[:,12]


featsTrain = traindata.values[:,0:13]

featsTest = testdata.values[:,0:13]

lblsTrain = traindata.values[:,13]

lblsTest = testdata.values[:,13]

featsTest21 = testdata21.values[:,0:13]

lblsTest21 = testdata21.values[:,13]

#Start of Random Forest Model
modelR = es.RandomForestClassifier(n_estimators = 100, criterion = "entropy")
model21R = es.RandomForestClassifier(n_estimators = 100, criterion="entropy")
modelR.fit(featsTrain, lblsTrain)
lblsPredR = modelR.predict(featsTest)
for a,b in zip(lblsTest, lblsPredR):
    if a == b:
        countR += 1
        if a == 1:
            countNorm += 1
        elif a == 2:
            countDoS += 1
        elif a == 3:
            countProbe += 1
        elif a == 4:
            countR2L += 1
        elif a == 5:
            countU2R += 1
accR = (round(countR/(len(featsTest)), 3)) * 100
normaccR = (round(countNorm / len(normTest), 3)) * 100
DoSaccR = (round(countDoS / len(DoSTest), 3)) * 100
ProbeaccR = (round(countProbe / len(probeTest), 3)) * 100
R2LaccR = (round(countR2L / len(R2LTest), 3)) * 100
U2RaccR = (round(countU2R / len(U2RTest), 3)) * 100
countNorm = 0
countDoS = 0
countProbe = 0
countR2L = 0
countU2R = 0
print("\n\n\tWith NSL-KDD train and test data using Random Forest\n\nConfusion Matrix: \n", m.confusion_matrix(lblsTest, lblsPredR),"\n\n")
print(m.classification_report(lblsTest, lblsPredR))
print("\nAccuracy = ", accR, "%\n\nAccuracy of normal = ", normaccR, "%\nAccuracy of DoS = ", DoSaccR, "%\nAccuracy of Probe = ", ProbeaccR, "%\nAccuracy of R2L = ", R2LaccR, "%\nAccuracy of U2R = ", U2RaccR, "%\n")
print("-------------------------------------------------------\n")

# After training the models, pickle them
with open('modelR.pkl', 'wb') as fR:
    pickle.dump(modelR, fR)

modelRDiff = es.RandomForestClassifier(n_estimators = 100, criterion = "entropy")
modelRDiff.fit(featsTrainD, lblsTrainD)

# After training the models, pickle them
with open('modelRDiff.pkl', 'wb') as fR:
    pickle.dump(modelRDiff, fR)

import matplotlib.pyplot as plt
import sklearn.feature_selection as fs
rfecvR = fs.RFECV(estimator=modelR, scoring="accuracy").fit(featsTest, lblsTest)
plt.figure()
plt.xlabel("Number of Features Selected")
plt.ylabel("Cross Validation Score (nb of correct classifications)")
plt.title('RFECV Random Forest')
plt.plot(range(1, len(rfecvR.cv_results_['mean_test_score']) + 1), rfecvR.cv_results_['mean_test_score'])
plt.show()

#Start of Decision Tree Model


modelD = tr.DecisionTreeClassifier(criterion = "entropy", max_depth = 5)
model21D = tr.DecisionTreeClassifier(criterion = "entropy", max_depth = 5)
modelD.fit(featsTrain, lblsTrain)
lblsPredD = modelD.predict(featsTest)
for a,b in zip(lblsTest, lblsPredD):
    if a == b:
        countD += 1
        if a == 1:
            countNorm += 1
        elif a == 2:
            countDoS += 1
        elif a == 3:
            countProbe += 1
        elif a == 4:
            countR2L += 1
        elif a == 5:
            countU2R += 1
accD = (round(countD/(len(featsTest)), 3)) * 100
normaccD = (round(countNorm / len(normTest), 3)) * 100
DoSaccD = (round(countDoS / len(DoSTest), 3)) * 100
ProbeaccD = (round(countProbe / len(probeTest), 3)) * 100
R2LaccD = (round(countR2L / len(R2LTest), 3)) * 100
U2RaccD = (round(countU2R / len(U2RTest), 3)) * 100
countNorm = 0
countDoS = 0
countProbe = 0
countR2L = 0
countU2R = 0
print("\n\tWith NSL-KDD train and test data using Decision Tree\n\nConfusion Matrix: \n", m.confusion_matrix(lblsTest, lblsPredD),"\n\n")
print(m.classification_report(lblsTest, lblsPredD))
print("\nAccuracy = ", accD, "%\n\nAccuracy of normal = ", normaccD, "%\nAccuracy of DoS = ", DoSaccD, "%\nAccuracy of Probe = ", ProbeaccD, "%\nAccuracy of R2L = ", R2LaccD, "%\nAccuracy of U2R = ", U2RaccD, "%\n")
print("-------------------------------------------------------\n")

modelDDiff = tr.DecisionTreeClassifier(criterion = "entropy", max_depth = 5)
modelDDiff.fit(featsTrainD, lblsTrainD)

rfecvD = fs.RFECV(estimator = modelD, scoring = "accuracy").fit(featsTest, lblsTest)
plt.figure()
plt.xlabel("Features selected")
plt.ylabel("Cross Validation Score")
plt.title('RFECV Decision Tree')
plt.plot(range(1, len(rfecvD.grid_scores_) + 1), rfecvD.grid_scores_)


#End of Decision Tree Model

with open('modelDDiff.pkl', 'wb') as fD:
    pickle.dump(modelD, fD)

#Start of SVM Model


modelS = s.SVC(gamma = "auto", cache_size = 7000)
model21S = s.SVC(gamma = "auto", cache_size = 7000)
modelS.fit(featsTrain, lblsTrain)
lblsPredS = modelS.predict(featsTest)
for a,b in zip(lblsTest, lblsPredS):
    if a == b:
        countS += 1
        if a == 1:
            countNorm += 1
        elif a == 2:
            countDoS += 1
        elif a == 3:
            countProbe += 1
        elif a == 4:
            countR2L += 1
        elif a == 5:
            countU2R += 1
accS = (round(countS/(len(featsTest)), 3)) * 100
normaccS = (round(countNorm / len(normTest), 3)) * 100
DoSaccS = (round(countDoS / len(DoSTest), 3)) * 100
ProbeaccS = (round(countProbe / len(probeTest), 3)) * 100
R2LaccS = (round(countR2L / len(R2LTest), 3)) * 100
U2RaccS = (round(countU2R / len(U2RTest), 3)) * 100
countNorm = 0
countDoS = 0
countProbe = 0
countR2L = 0
countU2R = 0
print("\n\tWith NSL-KDD train and test data using SVM\n\nConfusion Matrix: \n", m.confusion_matrix(lblsTest, lblsPredS),"\n\n")
print(m.classification_report(lblsTest, lblsPredS))
print("\nAccuracy = ", accS, "%\n\nAccuracy of normal = ", normaccS, "%\nAccuracy of DoS = ", DoSaccS, "%\nAccuracy of Probe = ", ProbeaccS, "%\nAccuracy of R2L = ", R2LaccS, "%\nAccuracy of U2R = ", U2RaccS, "%\n")
print("-------------------------------------------------------\n")

modelSDiff = s.SVC(gamma="auto", cache_size = 7000)
modelSDiff.fit(featsTrainD, lblsTrainD)

with open('modelSDiff.pkl', 'wb') as fS:
    pickle.dump(modelS, fS)

# Load the pickled models before making predictions
with open('modelR.pkl', 'rb') as fR:
    modelR = pickle.load(fR)

# Load the pickled models before making predictions
with open('modelRDiff.pkl', 'rb') as fR:
    modelRDiff = pickle.load(fR)

with open('modelDDiff.pkl', 'rb') as fD:
    modelDDiff = pickle.load(fD)

with open('modelSDiff.pkl', 'rb') as fS:
    modelSDiff = pickle.load(fS)

# Function to handle prediction output
def print_prediction(prediction, model_name):
    if prediction == 1:
        print(f"\nUsing {model_name}: Attack detection predicts normal connection\n")
    elif prediction == 2:
        print(f"\nUsing {model_name}: Attack detection predicts possible DoS attack!\n")
    elif prediction == 3:
        print(f"\nUsing {model_name}: Attack detection predicts possible Probe attack!\n")
    elif prediction == 4:
        print(f"\nUsing {model_name}: Attack detection predicts R2L attack!\n")
    elif prediction == 5:
        print(f"\nUsing {model_name}: Attack detection predicts U2R attack!\n")

# Start of the loop for repeated user input and model prediction
while True:
    choice = str(input("\nDo you want to test specific input (y or n): "))

    if choice.lower() == "n":
        print("Exiting..")
        break  # Exit the loop and finish the process

    elif choice.lower() == 'y':
        print("\n1. TCP      2. ICMP\n3. UDP")
        a = int(input("Enter Protocol Type: "))
        if a <= 0 or a > 11:
            while a <= 0 or a > 3:
                print("\nWrong Input!... Try Again\n")
                a = int(input("\nEnter choice for protocol type (1-3): "))
                if a > 0 and a <= 3:
                    break
        print("\n1. SF      2. REJ\n3. RSTR      4. RSTO\n5. S0      6. S1\n7.S2      8. S3\n9. OTH      10. SH\n11. RSTOS0")
        b = int(input("\nEnter choice for status flag: "))
        if b <= 0 or b > 11:
            while b <= 0 or b > 11:
                print("\nWrong Input!... Try Again\n")
                b = int(input("\nEnter choice for status flag (1-11): "))
                if b > 0 and b <= 11:
                    break
        c = int(input("\nEnter Number of Source Bytes sent (int): "))
        d = int(input("\nEnter num_access_files (int): "))
        e = int(input("\nEnter 1 if the login is guest or 0 if it is not: "))
        if e < 0 or e > 1:
            while e < 0 or e > 1:
                print("\nWrong Input!... Try Again\n")
                e = int(input("Enter 1 if login is guest or 0 if it is not: "))
                if e >= 0 and e <= 1:
                    break
        f = int(input("\nEnter srv count (int): "))
        g = float(input("\nEnter diff srv rate (in decimal form) : "))
        h = float(input("\nEnter srv diff host rate (in decimal form) : "))
        i = float(input("\nEnter dst host same source port rate (in decimal form) : "))
        j = float(input("\nEnter dst host srv diff host rate (in decimal form) : "))
        k = float(input("\nEnter dst host srv serror rate (in decimal form) : "))
        m = float(input("Enter dst host srv rerror rate (in decimal form) : "))

        # Create the feature array from user input
        arrDiff = np.array([a, b, c, d, e, f, g, h, i, j, k, m])

        # Get predictions from the trained models
        lR = int(modelRDiff.predict(arrDiff.reshape(1, -1)))
        #lD = int(modelD.predict(arrDiff.reshape(1, -1)))
        #lS = int(modelS.predict(arrDiff.reshape(1, -1)))

        # Create the feature array for each model's input
        arrR = np.array([a, b, c, d, e, f, g, h, i, j, k, lR, m])
        #arrD = np.array([a, b, c, d, e, f, g, h, i, j, k, lD, m])
        #arrS = np.array([a, b, c, d, e, f, g, h, i, j, k, lS, m])

        # Get predictions from Random Forest, Decision Tree, and SVM models
        pPredR = modelR.predict(arrR.reshape(1, -1))
        print("\n\nUsing Random Forest Difficulty Level Prediction: ", lR, "\n")
        print_prediction(pPredR, "Random Forest")

        '''
        pPredD = modelD.predict(arrD.reshape(1, -1))
        print("Using Decision Tree Difficulty Level Prediction: ", lD, "\n")
        print_prediction(pPredD, "Decision Tree")

        pPredS = modelS.predict(arrS.reshape(1, -1))
        print("Using SVM Difficulty Level Prediction: ", lS, "\n")
        print_prediction(pPredS, "SVM")
        '''

